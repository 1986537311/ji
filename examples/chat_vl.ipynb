{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xinference supports multimodal models, such as: qwen-vl-chat. This notebook shows how to chat with large vision language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "First, you need to install Xinference:\n",
    "```shell\n",
    "pip install xinference\n",
    "```\n",
    "\n",
    "Then, start the Xinference server by the following command:\n",
    "```shell\n",
    "xinference\n",
    "```\n",
    "\n",
    "The Xinference server will be started:\n",
    "\n",
    "```shell\n",
    "2023-12-29 06:14:53,568 xinference.core.supervisor 9364 INFO     Xinference supervisor 0.0.0.0:21679 started\n",
    "2023-12-29 06:14:53,612 xinference.core.worker 9364 INFO     Xinference worker 0.0.0.0:21679 started\n",
    "2023-12-29 06:14:53,613 xinference.core.worker 9364 INFO     Purge cache directory: /home/codingl2k1/.xinference/cache\n",
    "2023-12-29 06:14:57,079 xinference.api.restful_api 9197 INFO     Starting Xinference at endpoint: http://0.0.0.0:9997\n",
    "```\n",
    "\n",
    "Finally, we launch a ChatGLM3 model for tool calls.\n",
    "```shell\n",
    "xinference launch -u my_vl_model -n qwen-vl-chat -f pytorch -t multimodal\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with large vision language model\n",
    "\n",
    "Xinference fully supports openai's image messages in both URL and base64 formats. This example shows how to encode an image in base64 bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "response = requests.get(\"http://i.epochtimes.com/assets/uploads/2020/07/shutterstock_675595789-600x400.jpg\")\n",
    "img = Image.frombytes(response.content)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "b64_img = base64.b64encode(response.content).decode(\"utf-8\")\n",
    "\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"图中有几条鱼？\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{b64_img}\",\n",
    "                    # Also, you can put an URL directly.\n",
    "                    # \"url\": f\"http://i.epochtimes.com/assets/uploads/2020/07/shutterstock_675595789-600x400.jpg\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "client = openai.Client(api_key=\"not empty\", base_url=f\"http://0.0.0.0:9997/v1\")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"my_vl_model\",\n",
    "    messages=messages,\n",
    ")\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Xinference is a powerful inference tool that supports not only tool calls but also vision language models which providing inference capabilities similar to gpt4v."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
