# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-12-29 15:20+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/getting_started/troubleshooting.rst:5
msgid "Troubleshooting"
msgstr "故障排除"

#: ../../source/getting_started/troubleshooting.rst:9
msgid "No huggingface repo access"
msgstr "没有 huggingface 仓库权限"

#: ../../source/getting_started/troubleshooting.rst:11
msgid ""
"Sometimes, you may face errors accessing huggingface models, such as the "
"following message when accessing `llama2`:"
msgstr ""
"获取模型时，有时候会遇到权限问题。比如在获取 ``llama2`` 模型时可能会有"
"以下提示："

#: ../../source/getting_started/troubleshooting.rst:18
msgid ""
"This typically indicates either a lack of access rights to the repository"
" or missing huggingface access tokens. The following sections provide "
"guidance on addressing these issues."
msgstr ""
"这种情况一般是缺少 huggingface 仓库的权限，或者是没有配置 huggingface "
"token。可以按照接下来的方式解决这个问题。"

#: ../../source/getting_started/troubleshooting.rst:22
msgid "Get access to the huggingface repo"
msgstr "申请 huggingface 仓库权限"

#: ../../source/getting_started/troubleshooting.rst:24
msgid ""
"To obtain access, navigate to the desired huggingface repository and "
"agree to its terms and conditions. As an illustration, for the `llama2` "
"model, you can use this link: `https://huggingface.co/meta-llama/Llama-2"
"-7b-hf <https://huggingface.co/meta-llama/Llama-2-7b-hf>`_."
msgstr ""
"想要获取访问权限，打开对应的 huggingface 仓库，同意其条款和注意事项。以 `"
"`llama2``为例，可以打开这个链接去申请：`https://huggingface.co/meta-llama"
"/Llama-2-7b-hf <https://huggingface.co/meta-llama/Llama-2-7b-hf>`_."

#: ../../source/getting_started/troubleshooting.rst:29
msgid "Set up credentials to access huggingface"
msgstr "设置访问 huggingface 凭证"

#: ../../source/getting_started/troubleshooting.rst:31
msgid ""
"Your credential to access huggingface can be found online at "
"`https://huggingface.co/settings/tokens "
"<https://huggingface.co/settings/tokens>`_."
msgstr ""
"可以在 huggingface 页面找到凭证，`https://huggingface.co/settings/tokens "
"<https://huggingface.co/settings/tokens>`_."

#: ../../source/getting_started/troubleshooting.rst:33
msgid ""
"You can set the token as an environmental variable, with ``export "
"HUGGING_FACE_HUB_TOKEN=your_token_here``."
msgstr ""
"可以通过设置环境变量设置访问凭证，``export HUGGING_FACE_HUB_TOKEN=your_"
"token_here``。"

#: ../../source/getting_started/troubleshooting.rst:36
msgid "Download models from ModelScope"
msgstr "从 ModelScope 下载模型"

#: ../../source/getting_started/troubleshooting.rst:38
msgid ""
"When the network connection to HuggingFace is blocked, you can also "
"choose to download models from ModelScope, especially for Chinese users. "
"For a detailed list of supported models and settings, please refer to "
":ref:`models_download`."
msgstr ""
"当你所在的网络访问 HuggingFace 有阻碍时，可以选择 ModelScope 作为模型下载"
"源，特别适合国内的用户。"

#: ../../source/getting_started/troubleshooting.rst:43
msgid "Incompatibility Between NVIDIA Driver and PyTorch Version"
msgstr "英伟达驱动和 PyTorch 版本不匹配"

#: ../../source/getting_started/troubleshooting.rst:45
msgid "If you are using a NVIDIA GPU, you may face the following error:"
msgstr "如果你在使用英伟达显卡，你可能会遇到以下错误："

#: ../../source/getting_started/troubleshooting.rst:56
msgid ""
"This typically indicates that your CUDA driver version is not compatible "
"with the PyTorch version you are using."
msgstr "这种情况一般是 CUDA 的版本和 Pytorch 版本不兼容导致的。"

#: ../../source/getting_started/troubleshooting.rst:58
msgid ""
"Go to `https://pytorch.org <https://pytorch.org>`_ to install a PyTorch "
"version that has been compiled with your version of the CUDA driver. **Do"
" not install a cuda version smaller than 11.8, preferably between 11.8 "
"and 12.1.**"
msgstr ""
"可以到 `https://pytorch.org <https://pytorch.org>`_ 官网安装和 CUDA 对应"
"的预编译版本的 PyTorch。同时，**请检查安装的 CUDA 版本不要小于 11.8，最好版本在 11.8 到 12.1之间。**"

#: ../../source/getting_started/troubleshooting.rst:61
msgid ""
"Say if your CUDA driver version is 11.8, then you can install PyTorch "
"with the following command:"
msgstr "比如你的 CUDA 版本是 11.8，可以使用以下命令安装对应的 PyTorch："

