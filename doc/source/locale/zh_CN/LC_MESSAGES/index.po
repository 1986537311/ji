# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-12-25 17:11+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/index.rst:4
msgid "Xorbits Inference: Model Serving Made Easyü§ñ"
msgstr "Xorbits InferenceÔºöËΩªÊùæÈÉ®ÁΩ≤Ê®°Âûã"

#: ../../source/index.rst:6
msgid ""
"Xorbits Inference(Xinference) is a powerful and versatile library "
"designed to serve language, speech recognition, and multimodal models. "
"With Xorbits Inference, you can effortlessly deploy and serve your or "
"state-of-the-art built-in models using just a single command. Whether you"
" are a researcher, developer, or data scientist, Xorbits Inference "
"empowers you to unleash the full potential of cutting-edge AI models."
msgstr ""

#: ../../source/index.rst:14
msgid "Key Features"
msgstr ""

#: ../../source/index.rst:16
msgid ""
"üåü **Model Serving Made Easy**: Simplify the process of serving large "
"language, speech recognition, and multimodal models. You can set up and "
"deploy your models for experimentation and production with a single "
"command."
msgstr ""

#: ../../source/index.rst:20
msgid ""
"‚ö°Ô∏è **State-of-the-Art Models**: Experiment with cutting-edge built-in "
"models using a single command. Inference provides access to state-of-the-"
"art open-source models!"
msgstr ""

#: ../../source/index.rst:23
msgid ""
"üñ• **Heterogeneous Hardware Utilization**: Make the most of your hardware "
"resources with `ggml <https://github.com/ggerganov/ggml>`_. Xorbits "
"Inference intelligently utilizes heterogeneous hardware, including GPUs "
"and CPUs, to accelerate your model inference tasks."
msgstr ""

#: ../../source/index.rst:27
msgid ""
"‚öôÔ∏è **Flexible API and Interfaces**: Offer multiple interfaces for "
"interacting with your models, supporting RPC, RESTful API(compatible with"
" OpenAI API), CLI and WebUI for seamless management and monitoring."
msgstr ""

#: ../../source/index.rst:31
msgid ""
"üåê **Distributed Deployment**: Excel in distributed deployment scenarios, "
"allowing the seamless distribution of model inference across multiple "
"devices or machines."
msgstr ""

#: ../../source/index.rst:34
msgid ""
"üîå **Built-in Integration with Third-Party Libraries**: Xorbits Inference "
"seamlessly integrates with popular third-party libraries like `LangChain "
"<https://python.langchain.com/docs/integrations/providers/xinference>`_ ,"
" `LlamaIndex <https://gpt-index.readthedocs.io/en/stable/examples/llm/"
"XinferenceLocalDeployment.html#i-run-pip-install-xinference-all-in-a-"
"terminal-window>`_ , `Dify <https://docs.dify.ai/advanced/model-"
"configuration/xinference>`_ , and `Chatbox <https://chatboxai.app/>`_."
msgstr ""

#: ../../source/index.rst:42
msgid "üî• Hot Topics"
msgstr ""

#: ../../source/index.rst:45
msgid "Framework Enhancements"
msgstr ""

#: ../../source/index.rst:46
msgid "Auto recover: `#694 <https://github.com/xorbitsai/inference/pull/694>`_"
msgstr ""

#: ../../source/index.rst:47
msgid ""
"Function calling API: `#701 "
"<https://github.com/xorbitsai/inference/pull/701>`_ , here's example: "
"https://github.com/xorbitsai/inference/blob/main/examples/FunctionCall.ipynb"
msgstr ""

#: ../../source/index.rst:48
msgid ""
"Support rerank model: `#672 "
"<https://github.com/xorbitsai/inference/pull/672>`_"
msgstr ""

#: ../../source/index.rst:49
msgid ""
"Speculative decoding: `#509 "
"<https://github.com/xorbitsai/inference/pull/509>`_"
msgstr ""

#: ../../source/index.rst:50
msgid ""
"Support grammar-based sampling for ggml models: `#525 "
"<https://github.com/xorbitsai/inference/pull/525>`_"
msgstr ""

#: ../../source/index.rst:51
msgid ""
"Incorporate vLLM: `#445 "
"<https://github.com/xorbitsai/inference/pull/445>`_"
msgstr ""

#: ../../source/index.rst:55
msgid "New Models"
msgstr ""

#: ../../source/index.rst:56
msgid ""
"Built-in support for `Yi <https://huggingface.co/01-ai>`_: `#629 "
"<https://github.com/xorbitsai/inference/pull/629>`_"
msgstr ""

#: ../../source/index.rst:57
msgid ""
"Built-in support for `zephyr-7b-alpha "
"<https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha>`_ and `zephyr-7b-"
"beta <https://huggingface.co/HuggingFaceH4/zephyr-7b-beta>`_: `#597 "
"<https://github.com/xorbitsai/inference/pull/597>`_"
msgstr ""

#: ../../source/index.rst:58
msgid ""
"Built-in support for `chatglm3 "
"<https://huggingface.co/THUDM/chatglm3-6b): "
"[#587](https://github.com/xorbitsai/inference/pull/587>`_"
msgstr ""

#: ../../source/index.rst:59
msgid ""
"Built-in support for `mistral-v0.1 <https://huggingface.co/mistralai"
"/Mistral-7B-v0.1>`_ and `mistral-instruct-v0.1 "
"<https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1>`_: `#510 "
"<https://github.com/xorbitsai/inference/pull/510>`_"
msgstr ""

#: ../../source/index.rst:63
msgid "Integrations"
msgstr ""

#: ../../source/index.rst:64
msgid ""
"`Dify <https://docs.dify.ai/advanced/model-configuration/xinference>`_: "
"an LLMOps platform that enables developers (and even non-developers) to "
"quickly build useful applications based on large language models, "
"ensuring they are visual, operable, and improvable."
msgstr ""

#: ../../source/index.rst:65
msgid ""
"`Chatbox <https://chatboxai.app/>`_: a desktop client for multiple "
"cutting-edge LLM models, available on Windows, Mac and Linux."
msgstr ""

#: ../../source/index.rst:69
msgid "License"
msgstr ""

#: ../../source/index.rst:70
msgid "`Apache 2 <https://github.com/xorbitsai/inference/blob/main/LICENSE>`_"
msgstr ""

#~ msgid ""
#~ "Embedding model support: `#418 "
#~ "<https://github.com/xorbitsai/inference/pull/418>`_"
#~ msgstr ""

#~ msgid ""
#~ "LoRA support: `#271 "
#~ "<https://github.com/xorbitsai/inference/issues/271>`_"
#~ msgstr ""

#~ msgid ""
#~ "Multi-GPU support for PyTorch models:"
#~ " `#226 <https://github.com/xorbitsai/inference/issues/226>`_"
#~ msgstr ""

#~ msgid ""
#~ "Xinference dashboard: `#93 "
#~ "<https://github.com/xorbitsai/inference/issues/93>`_"
#~ msgstr ""

#~ msgid ""
#~ "Built-in support for `CodeLLama "
#~ "<https://github.com/facebookresearch/codellama>`_: `#414 "
#~ "<https://github.com/xorbitsai/inference/pull/414>`_ `#402 "
#~ "<https://github.com/xorbitsai/inference/pull/402>`_"
#~ msgstr ""

