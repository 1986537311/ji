# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2023, Xorbits Inc.
# This file is distributed under the same license as the Xinference package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Xinference \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-10-16 10:33+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../source/models/custom.rst:5
msgid "Custom Models"
msgstr "自定义模型"

#: ../../source/models/custom.rst:6
msgid ""
"Xinference provides a flexible and comprehensive way to integrate, "
"manage, and utilize custom models."
msgstr ""
"Xinference 提供了一种灵活而全面的方式来集成、管理和应用自定义模型。"

#: ../../source/models/custom.rst:9
msgid "Define a custom model"
msgstr ""
"定义自定义模型"

#: ../../source/models/custom.rst:11
msgid "Define a custom model based on the following template:"
msgstr "基于以下模板定义一个自定义模型："

#: ../../source/models/custom.rst:50
msgid ""
"model_name: A string defining the name of the model. The name must start "
"with a letter or a digit and can only contain letters, digits, "
"underscores, or dashes."
msgstr ""
"model_name: 模型名称。名称必须以字母或数字开头，且只能包含字母、数字、下划线或短划线。"

#: ../../source/models/custom.rst:51
msgid ""
"context_length: context_length: An optional integer that specifies the "
"maximum context size the model was trained to accommodate, encompassing "
"both the input and output lengths. If not defined, the default value is "
"2048 tokens (~1,500 words)."
msgstr ""
"context_length: 一个可选的整数，模型支持的最大上下文长度，包括输入和输出长度。如果未定义，默认值为2048个token（约1,500个词）。"

#: ../../source/models/custom.rst:52
msgid ""
"model_lang: A list of strings representing the supported languages for "
"the model. Example: [\"en\"], which means that the model supports "
"English."
msgstr ""
"model_lang: 一个字符串列表，表示模型支持的语言。例如：['en']，表示该模型支持英语。"

#: ../../source/models/custom.rst:53
msgid ""
"model_ability: A list of strings defining the abilities of the model. It "
"could include options like \"embed\", \"generate\", and \"chat\". In this"
" case, the model has the ability to \"generate\"."
msgstr ""
"model_ability: 一个字符串列表，定义模型的能力。它可以包括像 'embed'、'generate' 和 'chat' 这样的选项。"
"示例表示模型具有 'generate' 的能力。"

#: ../../source/models/custom.rst:59
msgid ""
"model_specs: An array of objects defining the specifications of the "
"model. These include:"
msgstr ""
"model_specs: 一个包含定义模型规格的对象数组。这些规格包括："

#: ../../source/models/custom.rst:55
msgid ""
"model_format: A string that defines the model format, could be "
"\"pytorch\" or \"ggmlv3\"."
msgstr ""
"model_format: 一个定义模型格式的字符串，可以是 'pytorch' 或 'ggmlv3'。"

#: ../../source/models/custom.rst:56
msgid ""
"model_size_in_billions: An integer defining the size of the model in "
"billions of parameters."
msgstr ""
"model_size_in_billions: 一个整数，定义模型的参数量，以十亿为单位。"

#: ../../source/models/custom.rst:57
msgid ""
"quantizations: A list of strings defining the available quantizations for"
" the model. For PyTorch models, it could be \"4-bit\", \"8-bit\", or "
"\"none\". For ggmlv3 models, the quantizations should correspond to "
"values that work with the ``model_file_name_template``."
msgstr ""
"quantizations: 一个字符串列表，定义模型的量化方式。"
"对于 PyTorch 模型，它可以是 \"4-bit\"、\"8-bit\" 或 \"none\"。"
"对于 ggmlv3 模型，量化方式应与 ``model_file_name_template`` 中的值对应。"

#: ../../source/models/custom.rst:58
msgid ""
"model_id: A string representing the model ID, possibly referring to an "
"identifier used by Hugging Face."
msgstr ""
"model_id: 一个表示模型标识的字符串，类似 HuggingFace 或 ModelScope 使用的标识符。"

#: ../../source/models/custom.rst:59
msgid ""
"model_uri: A string representing the URI where the model can be loaded "
"from, such as \"file:///path/to/llama-2-7b\". If model URI is absent, "
"Xinference will try to download the model from Hugging Face with the "
"model ID."
msgstr ""
"model_uri: 表示模型的 URI 的字符串，例如 \"file:///path/to/llama-2-7b\"。"
"如果模型 URI 不存在，Xinference 将尝试使用 model_id 从 HuggingFace 或 ModelScope 下载模型。"

#: ../../source/models/custom.rst:60
msgid ""
"model_file_name_template: Required by ggml models. An f-string template "
"used for defining the model file name based on the quantization."
msgstr ""
"model_file_name_template: ggml 模型所需。一个 f-string 模板，用于根据量化定义模型文件名。"

#: ../../source/models/custom.rst:61
msgid ""
"prompt_style: An optional field that could be required by chat models to "
"define the style of prompts. The given example has this set to None, but "
"additional details could be found in a referenced file "
"xinference/model/llm/tests/test_utils.py."
msgstr ""
"prompt_style: 一个可选字段，chat 模型可能需要定义提示词样式。"
"给定的示例将其设置为 None，但可以在引用的文件 xinference/model/llm/tests/test_utils.py 中找到更多详细信息。"

#: ../../source/models/custom.rst:65
msgid "Register a Custom Model"
msgstr "注册一个自定义模型"

#: ../../source/models/custom.rst:67
msgid "Register a custom model programmatically:"
msgstr "以代码的方式注册自定义模型"

#: ../../source/models/custom.rst:82 ../../source/models/custom.rst:97
#: ../../source/models/custom.rst:112 ../../source/models/custom.rst:167
msgid "Or via CLI:"
msgstr "以命令行的方式"

#: ../../source/models/custom.rst:89
msgid "List the Built-in and Custom Models"
msgstr "列举内置和自定义模型"

#: ../../source/models/custom.rst:91
msgid "List built-in and custom models programmatically:"
msgstr "以代码的方式列举内置和自定义模型"

#: ../../source/models/custom.rst:104
msgid "Launch the Custom Model"
msgstr "启动自定义模型"

#: ../../source/models/custom.rst:106
msgid "Launch the custom model programmatically:"
msgstr "以代码的方式启动自定义模型"

#: ../../source/models/custom.rst:119
msgid "Interact with the Custom Model"
msgstr "使用自定义模型"

#: ../../source/models/custom.rst:121
msgid "Invoke the model programmatically:"
msgstr "以代码的方式调用模型"

#: ../../source/models/custom.rst:128
msgid "Result:"
msgstr "结果为："

#: ../../source/models/custom.rst:152
msgid "Or via CLI, replace ``${UID}`` with real model UID:"
msgstr "或者以命令行的方式，用实际的模型 UID 替换 ``${UID}``："

#: ../../source/models/custom.rst:159
msgid "Unregister the Custom Model"
msgstr "注销自定义模型"

#: ../../source/models/custom.rst:161
msgid "Unregister the custom model programmatically:"
msgstr "以代码的方式注销自定义模型"

